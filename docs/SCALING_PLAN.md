# üöÄ Plano de Escalonamento - Sistema RAG Multi-Per√≠odo Hist√≥rico

## üìã Vis√£o Geral

Transformar o chatbot atual (focado em Galileu Galilei) em um sistema escal√°vel capaz de responder perguntas sobre m√∫ltiplas figuras hist√≥ricas e per√≠odos da humanidade.

---

## üéØ Objetivos

1. **Escala Horizontal**: Suportar m√∫ltiplas figuras hist√≥ricas (Galileu, Newton, Einstein, etc.)
2. **Escala Temporal**: Cobrir diferentes per√≠odos hist√≥ricos (Renascimento, Iluminismo, Revolu√ß√£o Cient√≠fica, etc.)
3. **Especializa√ß√£o**: Modelos especializados por dom√≠nio usando Mixture of Experts (MoE)
4. **Efici√™ncia**: Manter infer√™ncia eficiente com QLoRA
5. **Precis√£o Hist√≥rica**: Valida√ß√£o de fatos e cita√ß√µes como guardrails

---

## üèóÔ∏è Arquitetura Proposta

### 1. Multi-Collection Vector Store (ChromaDB)

```
data/vectorstore/
‚îú‚îÄ‚îÄ renaissance/
‚îÇ   ‚îú‚îÄ‚îÄ galileo_galilei/
‚îÇ   ‚îú‚îÄ‚îÄ leonardo_da_vinci/
‚îÇ   ‚îî‚îÄ‚îÄ michelangelo/
‚îú‚îÄ‚îÄ enlightenment/
‚îÇ   ‚îú‚îÄ‚îÄ isaac_newton/
‚îÇ   ‚îú‚îÄ‚îÄ voltaire/
‚îÇ   ‚îî‚îÄ‚îÄ john_locke/
‚îú‚îÄ‚îÄ modern_physics/
‚îÇ   ‚îú‚îÄ‚îÄ albert_einstein/
‚îÇ   ‚îú‚îÄ‚îÄ marie_curie/
‚îÇ   ‚îî‚îÄ‚îÄ niels_bohr/
‚îî‚îÄ‚îÄ metadata/
    ‚îú‚îÄ‚îÄ temporal_index.json
    ‚îú‚îÄ‚îÄ thematic_index.json
    ‚îî‚îÄ‚îÄ cross_references.json
```

**Vantagens**:
- Isolamento de contextos por per√≠odo/figura
- Busca eficiente dentro de dom√≠nios espec√≠ficos
- Facilita manuten√ß√£o e atualiza√ß√£o incremental

### 2. Topic-Based Routing System

```python
class TopicRouter:
    """
    Roteador inteligente que direciona queries para a collection apropriada
    """
    
    def __init__(self):
        self.classifiers = {
            'temporal': TemporalClassifier(),    # S√©culo/per√≠odo
            'thematic': ThematicClassifier(),    # F√≠sica/Astronomia/etc
            'entity': EntityRecognizer()         # Nome da figura
        }
    
    def route_query(self, query: str) -> List[str]:
        """
        Retorna lista de collections relevantes para a query
        
        Exemplo:
        Query: "Como Newton e Einstein viam a gravidade?"
        Return: ['enlightenment/isaac_newton', 'modern_physics/albert_einstein']
        """
        pass
```

### 3. Hybrid Retrieval (Dense + Sparse)

**Dense Retrieval** (j√° implementado):
- Embeddings sem√¢nticos (sentence-transformers)
- Captura rela√ß√µes conceituais
- Bom para queries abstratas

**Sparse Retrieval** (a implementar):
- BM25 ou TF-IDF
- Captura keywords exatos (nomes, datas, lugares)
- Bom para queries factuais

```python
class HybridRetriever:
    """
    Combina busca densa (semantic) e esparsa (keyword)
    """
    
    def __init__(self, vectorstore, bm25_index):
        self.dense_retriever = vectorstore.as_retriever()
        self.sparse_retriever = BM25Retriever(bm25_index)
    
    def retrieve(self, query: str, k: int = 10) -> List[Document]:
        """
        Retorna top-k documentos combinando ambas as estrat√©gias
        """
        dense_docs = self.dense_retriever.get_relevant_documents(query)
        sparse_docs = self.sparse_retriever.get_relevant_documents(query)
        
        # Reciprocal Rank Fusion (RRF) para combinar rankings
        return self._reciprocal_rank_fusion(dense_docs, sparse_docs, k)
```

---

## ü§ñ Mixture of Experts (MoE) Architecture

### Conceito

Em vez de um √∫nico LLM generalista, usar m√∫ltiplos modelos especializados:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Router LLM (pequeno)        ‚îÇ
‚îÇ  "Qual especialista deve responder?" ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ                ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Physics    ‚îÇ  ‚îÇ  Biography  ‚îÇ  ‚îÇ  Philosophy ‚îÇ
‚îÇ   Expert     ‚îÇ  ‚îÇ   Expert    ‚îÇ  ‚îÇ   Expert    ‚îÇ
‚îÇ (Fine-tuned) ‚îÇ  ‚îÇ (Fine-tuned)‚îÇ  ‚îÇ (Fine-tuned)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Implementa√ß√£o com QLoRA

```python
class ExpertMoE:
    """
    Mixture of Experts com QLoRA para efici√™ncia
    """
    
    def __init__(self):
        # Router leve para classifica√ß√£o r√°pida
        self.router = self._load_router()
        
        # Experts especializados (loaded on-demand)
        self.experts = {
            'physics': None,      # Llama fine-tuned em f√≠sica
            'biography': None,    # Llama fine-tuned em biografias
            'philosophy': None,   # Llama fine-tuned em filosofia
        }
        
    def query(self, question: str, context: str) -> str:
        # 1. Router decide qual expert usar
        expert_type = self.router.classify(question)
        
        # 2. Carrega expert (lazy loading para economizar VRAM)
        if self.experts[expert_type] is None:
            self.experts[expert_type] = self._load_expert(expert_type)
        
        # 3. Expert gera resposta
        return self.experts[expert_type].generate(question, context)
    
    def _load_expert(self, expert_type: str):
        """
        Carrega expert com QLoRA 4-bit
        """
        return HuggingFacePipeline.from_pretrained(
            f"models/{expert_type}_expert",
            load_in_4bit=True,
            bnb_config=self.qlora_config
        )
```

**Vantagens**:
- Cada expert √© menor e mais especializado
- QLoRA permite m√∫ltiplos experts em 4GB VRAM (load on-demand)
- Melhor qualidade em dom√≠nios espec√≠ficos

---

## üìä Pipeline de Ingest√£o Automatizada

### Estrutura de Metadados Rica

```python
class DocumentMetadata:
    """
    Metadados enriquecidos para cada chunk
    """
    
    # Identifica√ß√£o
    source_document: str
    chunk_id: int
    
    # Temporal
    period: str              # "Renaissance", "Enlightenment", etc.
    start_year: int          # 1564
    end_year: int            # 1642
    century: int             # 16, 17, 18, etc.
    
    # Geogr√°fica
    primary_location: str    # "Italy", "England", etc.
    secondary_locations: List[str]
    
    # Tem√°tica
    main_topics: List[str]   # ["physics", "astronomy"]
    keywords: List[str]      # ["telescope", "jupiter", "moons"]
    
    # Entidades
    main_figure: str         # "Galileo Galilei"
    mentioned_figures: List[str]  # ["Copernicus", "Pope Urban VIII"]
    
    # Cross-refer√™ncias
    related_chunks: List[int]
    contradicts_chunks: List[int]
```

### Pipeline Automatizado

```python
class DocumentIngestionPipeline:
    """
    Pipeline para processar e inserir novos documentos
    """
    
    def ingest_document(self, pdf_path: str, metadata: Dict):
        """
        Pipeline completo:
        1. Extra√ß√£o de texto
        2. Chunking inteligente
        3. Extra√ß√£o de metadados
        4. Enriquecimento (NER, temporal extraction)
        5. Cross-referencing
        6. Inser√ß√£o no vector store
        """
        
        # 1. Extra√ß√£o
        text = self.pdf_loader.load(pdf_path)
        
        # 2. Chunking sem√¢ntico (considera estrutura do documento)
        chunks = self.semantic_chunker.split(text)
        
        # 3. NER para extrair entidades
        for chunk in chunks:
            chunk.metadata.update({
                'mentioned_figures': self.ner.extract_persons(chunk.text),
                'locations': self.ner.extract_locations(chunk.text),
                'dates': self.temporal_extractor.extract_dates(chunk.text),
                'topics': self.topic_classifier.classify(chunk.text),
            })
        
        # 4. Cross-referencing
        self.cross_referencer.link_chunks(chunks)
        
        # 5. Inser√ß√£o na collection apropriada
        collection_name = self._determine_collection(metadata)
        self.vectorstore.add_to_collection(collection_name, chunks)
```

---

## üéì Datasets Dispon√≠veis

### 1. **Wikipedia** (wikimedia/wikipedia)
- **77.4K downloads**
- Multilingual (300+ idiomas)
- Biografias de figuras hist√≥ricas
- **Uso**: Base principal para biografias e contexto hist√≥rico

### 2. **Wikipedia Biography Dataset** (BetterHF/wikipedia-biography-dataset)
- **127 downloads**
- Focado em biografias
- **Uso**: Treinamento de expert em biografias

### 3. **Wikipedia Embeddings** (Cohere/wikipedia-2023-11-embed-multilingual-v3)
- **12.5K downloads**
- Embeddings pr√©-computados
- **Uso**: Acelerar busca sem√¢ntica

### 4. **RAG Mini Wikipedia** (rag-datasets/rag-mini-wikipedia)
- **3.3K downloads**
- Dataset espec√≠fico para RAG
- **Uso**: Testes e valida√ß√£o

---

## üõ†Ô∏è Estrutura de C√≥digo Atualizada

```
Langchain_Project/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ settings.py                 # Configura√ß√µes gerais
‚îÇ   ‚îî‚îÄ‚îÄ experts_config.py           # Config dos experts MoE
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                        # PDFs organizados por per√≠odo
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ renaissance/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ enlightenment/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ modern_era/
‚îÇ   ‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îî‚îÄ‚îÄ vectorstore/                # Multi-collection
‚îÇ       ‚îú‚îÄ‚îÄ renaissance/
‚îÇ       ‚îú‚îÄ‚îÄ enlightenment/
‚îÇ       ‚îî‚îÄ‚îÄ modern_era/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pdf_processor.py       # Processamento avan√ßado de PDFs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metadata_extractor.py  # NER, temporal extraction
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pipeline.py             # Pipeline automatizado
‚îÇ   ‚îú‚îÄ‚îÄ retrieval/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hybrid_retriever.py    # Dense + Sparse
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ topic_router.py        # Roteamento por t√≥pico
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cross_reference.py     # Sistema de cross-refs
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ moe.py                 # Mixture of Experts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ expert_loader.py       # Carregamento de experts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ router.py              # Router LLM
‚îÇ   ‚îú‚îÄ‚îÄ evaluation/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ accuracy_metrics.py    # M√©tricas de precis√£o hist√≥rica
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ citation_validator.py  # Valida√ß√£o de cita√ß√µes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ benchmarks.py          # Benchmarks de performance
‚îÇ   ‚îú‚îÄ‚îÄ chains/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ multi_expert_chain.py  # Chain com MoE
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ temporal_utils.py      # Utilities temporais
‚îÇ       ‚îî‚îÄ‚îÄ entity_utils.py        # Utilities de entidades
‚îú‚îÄ‚îÄ experts/                        # Modelos especializados
‚îÇ   ‚îú‚îÄ‚îÄ physics_expert/
‚îÇ   ‚îú‚îÄ‚îÄ biography_expert/
‚îÇ   ‚îî‚îÄ‚îÄ philosophy_expert/
‚îî‚îÄ‚îÄ tests/
    ‚îú‚îÄ‚îÄ test_routing.py
    ‚îú‚îÄ‚îÄ test_retrieval.py
    ‚îî‚îÄ‚îÄ test_accuracy.py
```

---

## üìà M√©tricas de Avalia√ß√£o

### 1. Precis√£o Hist√≥rica

```python
class HistoricalAccuracyMetric:
    """
    Valida se as respostas cont√™m informa√ß√µes historicamente precisas
    """
    
    def evaluate(self, answer: str, ground_truth: Dict) -> float:
        """
        Verifica:
        - Datas corretas
        - Nomes corretos
        - Eventos na ordem certa
        - Sem anacronismos
        """
        score = 0.0
        
        # Validar datas
        if self._validate_dates(answer, ground_truth['dates']):
            score += 0.3
        
        # Validar nomes
        if self._validate_entities(answer, ground_truth['entities']):
            score += 0.3
        
        # Validar eventos
        if self._validate_timeline(answer, ground_truth['timeline']):
            score += 0.4
        
        return score
```

### 2. Valida√ß√£o de Cita√ß√µes

```python
class CitationValidator:
    """
    Verifica se as cita√ß√µes est√£o corretas e bem atribu√≠das
    """
    
    def validate(self, answer: str, sources: List[Document]) -> Dict:
        """
        Retorna:
        - Cita√ß√µes encontradas
        - Cita√ß√µes corretas
        - Cita√ß√µes sem fonte
        - Score de confiabilidade
        """
        pass
```

### 3. Coverage Metrics

```python
class CoverageMetrics:
    """
    Mede a cobertura do conhecimento hist√≥rico
    """
    
    def calculate_coverage(self) -> Dict:
        """
        Retorna:
        - Per√≠odos cobertos
        - Figuras por per√≠odo
        - T√≥picos por figura
        - Gaps no conhecimento
        """
        pass
```

---

## üö¶ Roadmap de Implementa√ß√£o

### Fase 1: Prepara√ß√£o dos Dados (Semanas 1-2)
- [ ] Coletar/criar PDFs para figuras-chave
- [ ] Estruturar diret√≥rios por per√≠odo
- [ ] Implementar pipeline de ingest√£o automatizada
- [ ] Extrair metadados ricos

### Fase 2: Multi-Collection Vector Store (Semanas 3-4)
- [ ] Refatorar para suportar m√∫ltiplas collections
- [ ] Implementar topic-based routing
- [ ] Adicionar BM25 para hybrid retrieval
- [ ] Sistema de cross-refer√™ncias

### Fase 3: Mixture of Experts (Semanas 5-7)
- [ ] Treinar/fine-tune experts especializados
- [ ] Implementar router LLM
- [ ] Sistema de lazy loading
- [ ] Testes de performance

### Fase 4: Avalia√ß√£o e Guardrails (Semanas 8-9)
- [ ] Implementar m√©tricas de precis√£o hist√≥rica
- [ ] Sistema de valida√ß√£o de cita√ß√µes
- [ ] Testes de cobertura
- [ ] Benchmarks comparativos

### Fase 5: Interface e Deploy (Semanas 10-12)
- [ ] Interface aprimorada (seletor de per√≠odos)
- [ ] Visualiza√ß√µes temporais
- [ ] Sistema de feedback
- [ ] Documenta√ß√£o completa

---

## üí° Figuras Priorit√°rias para Implementa√ß√£o

### Renascimento (1400-1600)
1. **Leonardo da Vinci** - Pol√≠mata
2. **Galileo Galilei** - Astronomia/F√≠sica (j√° implementado)
3. **Michelangelo** - Arte/Escultura

### Iluminismo (1650-1800)
1. **Isaac Newton** - F√≠sica/Matem√°tica
2. **Voltaire** - Filosofia
3. **Benjamin Franklin** - Ci√™ncia/Pol√≠tica

### Era Moderna (1800-1950)
1. **Charles Darwin** - Biologia/Evolu√ß√£o
2. **Albert Einstein** - F√≠sica/Relatividade
3. **Marie Curie** - Qu√≠mica/Radioatividade

### Era Contempor√¢nea (1950-)
1. **Richard Feynman** - F√≠sica Qu√¢ntica
2. **Stephen Hawking** - Cosmologia
3. **Carl Sagan** - Astronomia/Divulga√ß√£o

---

## üì¶ Depend√™ncias Adicionais

```python
# requirements_scaling.txt

# Adicionar ao requirements.txt atual:

# NER e Processamento de Linguagem
spacy>=3.7.0
spacy-transformers>=1.3.0
# python -m spacy download pt_core_news_lg  # Modelo PT

# Sparse Retrieval
rank-bm25>=0.2.2

# Cross-referencing e Grafos
networkx>=3.2
pyvis>=0.3.2  # Visualiza√ß√£o de grafos

# Extra√ß√£o de Entidades Temporais
dateparser>=1.2.0
arrow>=1.3.0

# Fine-tuning (se for fazer)
peft>=0.7.0  # Para LoRA
datasets>=2.16.0

# M√©tricas e Avalia√ß√£o
evaluate>=0.4.1
rouge-score>=0.1.2
bert-score>=0.3.13

# Visualiza√ß√µes
plotly>=5.18.0
streamlit>=1.29.0  # Alternativa ao Gradio
```

---

## üéØ Benef√≠cios da Arquitetura

1. **Modularidade**: Cada componente pode ser atualizado independentemente
2. **Escalabilidade**: Adicionar nova figura = adicionar nova collection
3. **Efici√™ncia**: QLoRA + lazy loading para rodar em 4GB VRAM
4. **Precis√£o**: Experts especializados + valida√ß√£o de fatos
5. **Manutenibilidade**: C√≥digo organizado por responsabilidade
6. **Extensibilidade**: F√°cil adicionar novos per√≠odos/figuras

---

## üö® Desafios e Considera√ß√µes

### 1. Gest√£o de Mem√≥ria
- **Problema**: M√∫ltiplos experts podem exceder VRAM
- **Solu√ß√£o**: Lazy loading + offloading para CPU quando n√£o em uso

### 2. Consist√™ncia Hist√≥rica
- **Problema**: Informa√ß√µes contradit√≥rias entre fontes
- **Solu√ß√£o**: Sistema de vota√ß√£o + marca√ß√£o de incerteza

### 3. Cross-Period Queries
- **Problema**: "Compare Newton e Einstein"
- **Solu√ß√£o**: Multi-collection retrieval + s√≠ntese especializada

### 4. Qualidade dos Dados
- **Problema**: PDFs podem ter erros ou ser tendenciosos
- **Solu√ß√£o**: M√∫ltiplas fontes + valida√ß√£o cruzada

---

## üìö Pr√≥ximos Passos Imediatos

1. **Voc√™ fornecer√° PDFs sobre outras figuras/per√≠odos**
2. Implementaremos o pipeline de ingest√£o multi-collection
3. Desenvolveremos o sistema de routing
4. Testaremos com 2-3 figuras antes de escalar

---

## ü§ù Sugest√£o de Colabora√ß√£o

Para maximizar efici√™ncia, sugiro come√ßarmos com:

1. **3 figuras piloto** de per√≠odos diferentes:
   - Galileu (j√° implementado) - Renascimento
   - Newton - Iluminismo  
   - Einstein - Era Moderna

2. **Implementar primeiro**:
   - Multi-collection vector store
   - Topic routing b√°sico
   - Hybrid retrieval

3. **Depois adicionar**:
   - Experts MoE
   - Valida√ß√£o de precis√£o
   - Mais figuras

---

## üìù Conclus√£o

Esta arquitetura transforma seu chatbot de Galileu em uma plataforma robusta e escal√°vel para explorar a hist√≥ria da ci√™ncia. O uso de:

- **Multi-collections** para organiza√ß√£o
- **Hybrid retrieval** para precis√£o
- **MoE com QLoRA** para especializa√ß√£o eficiente
- **Rich metadata** para contexto
- **Validation metrics** para confiabilidade

... garante que o sistema pode crescer mantendo qualidade e performance.

**Pronto para come√ßar? Podemos iniciar pela prepara√ß√£o dos dados ou pela implementa√ß√£o do multi-collection vector store!**
